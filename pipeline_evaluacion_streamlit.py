"""
pipeline_evaluacion_streamlit.py
App Streamlit para evaluar el modelo MLP multisalida, mostrar m√©tricas y gr√°ficas interactivas.
"""
import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import json
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from tensorflow.keras.models import load_model # Importaci√≥n necesaria aqu√≠ para evitar NameError en load_resources

# Asume que estas funciones est√°n en utils/mlp_pipeline_utils.py
# Si no lo est√°n, aseg√∫rate de que existen o define las funciones
from utils.mlp_pipeline_utils import plot_boxplot_errores, plot_dispersion, plot_barras_metricas, plot_barras_r2,explicacion_metricas,explic_loss

# =================== CONFIGURACI√ìN Y CARGA DE RECURSOS ===================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(BASE_DIR, "modelos", "modelo_9vars_multisalida.keras")
X_SCALER_PATH = os.path.join(BASE_DIR, "modelos", "X_scaler_9vars.pkl")
Y_SCALER_PATH = os.path.join(BASE_DIR, "modelos", "y_scaler_4targets.pkl")
LE_AREA_PATH = os.path.join(BASE_DIR, "modelos", "label_encoder_tipo_area.pkl")
METRICS_PATH = os.path.join(BASE_DIR, "modelos", "metrics_9vars_multisalida.json")

FEATURES = [
    'PorcMortSem4','PorcMortSem5', 'PorcMortSem6','PesoSem4', 'PesoSem5', 'Pob Inicial',
    'Edad HTS', 'Edad Granja', 'Area'
]
TARGETS = ['Peso Prom. Final', 'Porc Consumo', 'ICA', 'Por_Mort._Final']

@st.cache_resource
def load_resources():
    # Asegurarse de que TensorFlow est√© cargado antes de load_model
    import tensorflow as tf
    try:
        model = load_model(MODEL_PATH)
        X_scaler = joblib.load(X_SCALER_PATH)
        y_scaler = joblib.load(Y_SCALER_PATH)
        le_area = None
        area_options = None
        if os.path.exists(LE_AREA_PATH):
            le_area = joblib.load(LE_AREA_PATH)
            area_options = le_area.classes_
        metrics_dict = None
        if os.path.exists(METRICS_PATH):
            with open(METRICS_PATH, "r") as f:
                metrics_dict = json.load(f)
        return model, X_scaler, y_scaler, le_area, area_options, metrics_dict
    except Exception as e:
        st.error(f"Error al cargar recursos esenciales: {e}. Verifique las rutas de los archivos.")
        return None, None, None, None, None, None

model, X_scaler, y_scaler, le_area, area_options, metrics_dict = load_resources()

if model is None:
    st.stop() # Detener si no se cargan los recursos

# =================== FUNCIONES DE PROCESAMIENTO Y PREDICCI√ìN ===================
def clean_data(df, le_area=None):
    """Limpia y codifica los datos de entrada."""
    df = df.copy()
    # Solo trabajamos con las features que el modelo necesita
    df_features_targets = df[[col for col in FEATURES + TARGETS if col in df.columns]].copy()
    df_features_targets = df_features_targets.dropna(subset=FEATURES)
    
    if 'Area' in FEATURES and le_area is not None and 'Area' in df_features_targets.columns:
        try:
            # La columna 'Area' debe ser string antes de la transformaci√≥n
            df_features_targets['Area'] = le_area.transform(df_features_targets['Area'].astype(str))
        except ValueError:
            st.warning("Advertencia: Se encontraron categor√≠as de 'Area' no vistas durante el entrenamiento. Los datos no codificables ser√°n omitidos.")
            # Si esto ocurre, podr√≠as necesitar una estrategia m√°s robusta (ej. imputaci√≥n, o saltar la fila)
            pass
            
    return df_features_targets

def predict_batch(df_features, model, X_scaler, y_scaler):
    """Realiza la predicci√≥n y deshace el escalado."""
    X_input_scaled = X_scaler.transform(df_features[FEATURES])
    y_pred_scaled = model.predict(X_input_scaled, verbose=0)
    y_pred_original = y_scaler.inverse_transform(y_pred_scaled)
    # Nombres de las columnas predichas
    results_df = pd.DataFrame(y_pred_original, columns=[f"{t}_Pred" for t in TARGETS])
    return results_df

# =================== INTERFAZ STREAMLIT ===================
st.set_page_config(
    page_title="Evaluaci√≥n MLP Multisalida",
    layout="wide",
    initial_sidebar_state="expanded"
)
st.title("üìä Evaluaci√≥n de Modelo MLP Multisalida")
st.markdown("---")
st.markdown("Sube tu archivo, escoge m√©tricas y gr√°ficas, y eval√∫a el modelo de forma interactiva.")

# Sidebar para selecci√≥n de m√©tricas y gr√°ficas
st.sidebar.header("Modo de predicci√≥n")
modo_prediccion = st.sidebar.radio("Selecciona el modo de predicci√≥n:", ["Manual", "Batch (archivo)"])

st.sidebar.header("Visualizaci√≥n de M√©tricas y Gr√°ficas")
metricas_opciones = [
    "MAE", "MSE", "RMSE", "MAPE", "R2", "Boxplot de errores", "Dispersi√≥n real vs predicho", "Barras de m√©tricas", "Barras de R2", "Curva de p√©rdida (Loss)"
]
metricas_seleccionadas = st.sidebar.multiselect(
    "Selecciona las m√©tricas y gr√°ficas a mostrar:",
    metricas_opciones,
    default=["MAE", "R2"]
)
modo = st.sidebar.selectbox(
    "Modo de evaluaci√≥n:",
    ("score", "cluster", "ranking")
)
n_clusters = None
rank_by = None
if modo == "cluster":
    n_clusters = st.sidebar.number_input("N√∫mero de clusters", min_value=2, max_value=20, value=3, step=1)
if modo == "ranking":
    rank_by = st.sidebar.selectbox("Columna para ranking", [f"{t}_Pred" for t in TARGETS])

# =================== L√ìGICA PRINCIPAL ===================
df_clean = None
results_df = None
df_out = None
uploaded_file = None # Inicializamos para evitar NameError

if modo_prediccion == "Manual":
    st.subheader("Predicci√≥n manual de variables")
    manual_inputs = {}
    
    # Formulario para entrada de Features
    with st.form("manual_input_form"):
        st.markdown("#### Variables de Entrada (Features)")
        cols_f = st.columns(3)
        for i, feat in enumerate(FEATURES):
            col_index = i % 3
            if feat == "Area" and area_options is not None:
                with cols_f[col_index]:
                    manual_inputs[feat] = st.selectbox(f"**{feat}**", area_options, key=f"man_f_{feat}")
            else:
                with cols_f[col_index]:
                    manual_inputs[feat] = st.number_input(f"**{feat}**", value=0.0, format="%0.4f", key=f"man_f_{feat}")

        # Formulario para entrada de Targets Reales (Opcional, para m√©tricas)
        st.markdown("---")
        st.markdown("#### Valores Reales (Targets - Opcional para m√©tricas)")
        st.info("Ingrese los valores reales si desea calcular el error para este punto de dato.")
        cols_t = st.columns(4)
        y_true_inputs = {}
        for i, target in enumerate(TARGETS):
            with cols_t[i]:
                # Usamos None o 0.0, pero None es mejor para saber si fue llenado
                y_true_inputs[target] = st.number_input(f"**{target}** (Real)", value=None, format="%0.4f", key=f"man_t_{target}")

        submitted = st.form_submit_button("üöÄ Predecir y Evaluar", type="primary")

    if submitted:
        # Construir DataFrame de una sola fila
        df_manual = pd.DataFrame([manual_inputs])
        
        # Codificar Area (si existe) y limpiar
        df_clean_manual = clean_data(df_manual, le_area)
        
        # Predicci√≥n
        results_df = predict_batch(df_clean_manual, model, X_scaler, y_scaler)
        
        # Concatenar resultados
        df_out = pd.concat([df_manual.reset_index(drop=True), results_df], axis=1)
        st.success("‚úÖ Predicci√≥n manual completada")
        
        st.subheader("Resultados Predichos")
        st.dataframe(df_out)
        
        # Evaluaci√≥n de m√©tricas (solo si se ingresaron todos los valores reales)
        y_true_values = {k: v for k, v in y_true_inputs.items() if v is not None}
        if len(y_true_values) == len(TARGETS):
            st.markdown("---")
            st.subheader("M√©tricas de Error para esta Instancia")
            
            y_true_array = np.array([list(y_true_values.values())])
            y_pred_array = results_df.values
            
            st.write(f"Error Absoluto Medio (MAE): {np.mean(np.abs(y_true_array - y_pred_array)):.4f}")
            # Puedes expandir esto para mostrar m√©tricas individuales si lo deseas.
        elif len(y_true_values) > 0:
            st.info("Para ver las m√©tricas de error para este punto, complete todos los valores reales.")
        


# =================== MODO BATCH (ARCHIVO) - L√≥gica Consolidada ===================
else: # modo_prediccion == "Batch (archivo)"
    st.subheader("Carga de Archivo para Evaluaci√≥n en Lote")
    st.info(f"üí° Para calcular las **m√©tricas y gr√°ficas de validaci√≥n** debe incluir las columnas {TARGETS} (valores reales) en el archivo.")
    
    uploaded_file = st.file_uploader(
        "Sube tu archivo Excel (.xlsx) o CSV (.csv) con las variables de entrada.",
        type=["xlsx", "csv", "xlsm"],
        key="file_uploader_eval"
    )
    
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
        except Exception as e:
            st.error(f"Error al leer el archivo: {e}")
            st.stop()

        missing_features = [f for f in FEATURES if f not in df.columns]
        if missing_features:
            st.error(f"‚ùå Faltan las siguientes columnas de **entrada (FEATURES)** en el archivo: {missing_features}")
            st.stop()
        
        # 1. Limpieza y preparaci√≥n (tambi√©n preserva TARGETS si existen)
        df_clean = clean_data(df, le_area)
        
        # 2. Predicci√≥n
        results_df = predict_batch(df_clean, model, X_scaler, y_scaler)
        
        # 3. Concatenaci√≥n de resultados (preserva FEATURES y TARGETS originales/limpios)
        df_out = pd.concat([df_clean.reset_index(drop=True), results_df], axis=1)

        # 4. Modo de evaluaci√≥n (Clustering / Ranking)
        if modo == "cluster":
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')
            clusters = kmeans.fit_predict(results_df)
            df_out['Cluster'] = clusters

        if modo == "ranking":
            df_out = df_out.sort_values(by=rank_by, ascending=False)
            df_out['Ranking'] = np.arange(1, len(df_out)+1)

        st.success("‚úÖ Evaluaci√≥n completada")
        st.subheader("Resultados de la Evaluaci√≥n (primeros 10 registros)")
        st.dataframe(df_out.head(10))
        csv = df_out.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="‚¨áÔ∏è Descargar resultados en CSV",
            data=csv,
            file_name="resultados_evaluacion.csv",
            mime="text/csv"
        )
        
        # =================== M√âTRICAS Y GR√ÅFICAS (Validaci√≥n con datos reales) ===================
        st.markdown("---")
        st.subheader("M√©tricas y Gr√°ficas de Validaci√≥n")
        
        # Verificar si las columnas TARGETS reales existen en el archivo cargado
        y_true_available = all(t in df_clean.columns for t in TARGETS)
        
        if y_true_available:
            
            # DataFrame de valores reales para la comparaci√≥n
            y_true_df = df_clean[TARGETS]
            y_pred_np = results_df.values
            
            # Mostrar M√©tricas Fijas (del archivo JSON guardado)
    if metrics_dict:
        st.markdown("#### M√©tricas Generales del Modelo (Datos de Entrenamiento/Validaci√≥n Guardados)")
        METRIC_EXPLANATIONS = explicacion_metricas()
        
        # Mostrar m√©tricas seleccionadas
        for met in metricas_seleccionadas:
            if met in ["MAE", "MSE", "MAPE", "R2", "RMSE"]:
                
                # Obtener la explicaci√≥n relevante
                exp = METRIC_EXPLANATIONS.get(met, {})
                
                # Usar st.expander para agrupar las m√©tricas y la explicaci√≥n
                # La m√©trica y su t√≠tulo se convierten en el encabezado del expander
                with st.expander(f"**{exp.get('title', met)}** üí°"):
                    
                    st.markdown(f"*{exp.get('info', 'M√©trica est√°ndar de regresi√≥n.')}*")
                    
                    # 1. Mostrar los valores de la m√©trica (tu c√≥digo original)
                    st.markdown("##### Valores por Variable (Modelo Entrenado):")
                    cols_met = st.columns(4)   # Reutilizar columnas para cada m√©trica
                    for i, var in enumerate(TARGETS):
                        with cols_met[i]:
                            # 1. L√≥gica para obtener el valor (RMSE requiere MSE)
                            if met == "RMSE":
                                mse_val = metrics_dict.get(var, {}).get("MSE", None)
                                valor = np.sqrt(mse_val) if mse_val is not None else None
                            else:
                                valor = metrics_dict.get(var, {}).get(met, None)
                            
                            if valor is not None:
                                
                                # 2. L√ìGICA DE FORMATO DE PORCENTAJE AGREGADA AQU√ç
                                if met in ["R2", "MAPE"]:
                                    # Multiplicar por 100 y formatear como porcentaje
                                    valor_formateado = f"{valor * 100:.2f} %" # Usamos .2f para precisi√≥n de porcentaje
                                else:
                                    # Para MAE, MSE, RMSE: Formato decimal est√°ndar
                                    valor_formateado = f"{valor:.4f}"
                                
                                # 3. Mostrar el valor con st.metric
                                st.metric(label=var, value=valor_formateado)
                            else:
                                st.metric(label=var, value="N/A")
                                
                    # 2. Mostrar la explicaci√≥n detallada al final
                    if exp.get('details'):
                        st.markdown("---")
                        st.markdown("##### An√°lisis de la M√©trica en el Negocio Av√≠cola:")
                        st.markdown(exp['details'])

            # Gr√°ficas generadas en tiempo real (requieren y_true_df)
            st.markdown("#### Evaluaci√≥n Gr√°fica del Lote Actual")
            
            # Boxplot de errores
            if "Boxplot de errores" in metricas_seleccionadas:
                    try:
                        st.write("Boxplot de Errores")
                        fig = plot_boxplot_errores(y_true_df, y_pred_np, TARGETS)
                        st.pyplot(fig)
                        plt.close('all')
                    except Exception as e:
                        st.info(f"No se pudo generar el Boxplot de errores: {e}")
                    
            # Dispersi√≥n real vs predicho
            if "Dispersi√≥n real vs predicho" in metricas_seleccionadas:
                    try:
                        st.write("Gr√°fico de Dispersi√≥n Real vs Predicho")
                        fig = plot_dispersion(y_true_df, y_pred_np, TARGETS)
                        st.pyplot(fig)
                        plt.close('all')
                    except Exception as e:
                        st.info(f"No se pudo generar el gr√°fico de Dispersi√≥n: {e}")
                    
            # Barras de m√©tricas y R2 (Calculadas para el LOTE actual)
            if "Barras de m√©tricas" in metricas_seleccionadas or "Barras de R2" in metricas_seleccionadas:
                metricas_batch = {}
                for i, var in enumerate(TARGETS):
                    y_true = y_true_df[var].values
                    y_pred = results_df[var + "_Pred"].values
                    
                    mae = np.mean(np.abs(y_true - y_pred))
                    mse = np.mean((y_true - y_pred)**2)
                    rmse = np.sqrt(mse)
                    # Evitar divisi√≥n por cero en MAPE y R2 si la varianza es cero
                    mape = np.mean(np.abs((y_true - y_pred) / y_true)) if np.all(y_true != 0) else 0 
                    
                    var_y = np.sum((y_true - np.mean(y_true))**2)
                    r2 = 1 - np.sum((y_true - y_pred)**2) / var_y if var_y != 0 else 0
                    
                    metricas_batch[var] = {"MAE": mae, "MSE": mse, "RMSE": rmse, "MAPE": mape, "R2": r2}
                    
                if "Barras de m√©tricas" in metricas_seleccionadas:
                        try:
                            st.write("Barras de M√©tricas (Lote Actual)")
                            fig = plot_barras_metricas(metricas_batch, TARGETS)
                            st.pyplot(fig)
                            plt.close('all')
                        except Exception as e:
                            st.info(f"No se pudo generar las barras de m√©tricas: {e}")
                        
                if "Barras de R2" in metricas_seleccionadas:
                        try:
                            st.write("Barras de R2 (Lote Actual)")
                            fig = plot_barras_r2(metricas_batch, TARGETS)
                            st.pyplot(fig)
                            plt.close('all')
                        except Exception as e:
                            st.info(f"No se pudo generar las barras de R2: {e}")
            
            # Curva de p√©rdida (Solo si se encuentra la imagen guardada)
            if "Curva de p√©rdida (Loss)" in metricas_seleccionadas:
                curva_path = os.path.join(BASE_DIR, "modelos", "curva_loss.png")
                if os.path.exists(curva_path):
                    st.image(curva_path, caption="Curva de p√©rdida (Loss)")
                    # 1.2 Insertar la explicaci√≥n concisa
                    mensaje = explic_loss()
                    st.markdown(mensaje)
                else:
                    st.info("No se encontr√≥ la curva de p√©rdida guardada.")
                    
        else:
            st.warning(f"‚ö†Ô∏è **M√©tricas Omitidas:** Para generar los Boxplots, Dispersi√≥n y calcular el R2 del lote actual, el archivo subido debe contener las columnas de **valores reales** ({TARGETS}).")

        
    else: # Si el archivo no se ha subido
        st.info("A la espera de la carga del archivo.")


